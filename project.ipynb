{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# COMP432 Project by Maxime Mahdavian and Artem Chernigel\n",
    "\n",
    "This jupyter notebook was included for convienience, but all of the test we conducted were on the Python files and thus this file is just these scripts copy/pasted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as tt\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "import datetime\n",
    "import device_function\n",
    "import ResNet as convnet\n",
    "import argparse\n",
    "import tensorflow\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, Flatten, Dropout,BatchNormalization ,Activation\n",
    "from keras.models import Model, Sequential\n",
    "from keras.applications.nasnet import NASNetLarge\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizer_v1 import Adam\n",
    "from keras.metrics import BinaryAccuracy\n",
    "from keras.metrics import Precision\n",
    "from keras.metrics import Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For using a GPU if available, finds an available device\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "\n",
    "# Puts some data into the device, particurlarly useful and required if using a GPU\n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "\n",
    "# Warp a dataloader to move data to device\n",
    "class DeviceDataloader():\n",
    "    def __init__(self, dataloader, device):\n",
    "        self.dataloader = dataloader\n",
    "        self.device = device\n",
    "\n",
    "    def __iter__(self):\n",
    "        for x in self.dataloader:\n",
    "            yield to_device(x, self.device)\n",
    "\n",
    "    # Number of batches\n",
    "    def __len__(self):\n",
    "        return len(self.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the accuracy\n",
    "# Input: tensor representing the output and truth labels associated with the output\n",
    "# Output: tensory of the accuracy\n",
    "def accuracy(output, label):\n",
    "    _, pred = torch.max(output, dim=1)\n",
    "    return torch.tensor(torch.sum(pred == label).item() / len(pred))\n",
    "\n",
    "\n",
    "# Base function for the ImageClassification. It handles all the steps throughout running the model\n",
    "# It allows more flexibility for recording data through the training of the model\n",
    "class ImageClassification(nn.Module):\n",
    "    # Feed forward method\n",
    "    # Input: Batch from the dataloader\n",
    "    # Output: Loss calculated with cross entropy\n",
    "    def training_step(self, batch):\n",
    "\n",
    "        image, label = batch\n",
    "        output = self(image)\n",
    "        loss = torch.nn.functional.cross_entropy(output, label)\n",
    "        return loss\n",
    "\n",
    "    # Feed forward during testing\n",
    "    # Input: Batch from a dataloader\n",
    "    # Output: Dictionary entry of the loss and accuracy\n",
    "    def testing_step(self, batch):\n",
    "        image, label = batch\n",
    "        output = self(image)\n",
    "        loss = torch.nn.functional.cross_entropy(output, label)\n",
    "        acc = accuracy(output, label)\n",
    "        return {'loss': loss.detach(), 'acc': acc}\n",
    "\n",
    "    # Collects several stats necessary to see how the model is performaning during training, namely\n",
    "    # accuracy and loss\n",
    "    # Input: Tensor representing the output of the model\n",
    "    # Output: Dictionary entry of the testing loss and testing accuracy\n",
    "    def testing_end(self, output):\n",
    "        batch_loss = [x['loss'] for x in output]\n",
    "        epoch_loss = torch.stack(batch_loss).mean()\n",
    "        batch_accuracy = [x['acc'] for x in output]\n",
    "        epoch_accuracy = torch.stack(batch_accuracy).mean()\n",
    "        return {'loss': epoch_loss.item(), 'acc': epoch_accuracy.item()}\n",
    "\n",
    "    # Displays the stats at the end of the epoch\n",
    "    # Input: epoch number, results of the epoch, time it took for the epoch and filename for logging\n",
    "    def epoch_end(self, epoch, result, time, file):\n",
    "        print(f\"Epoch [{epoch}], last_lr: {result['lrs'][-1]:.5f}, train_loss: {result['test_loss']:.4f}, \"\n",
    "              f\"test_loss: {result['loss']:.4f}, acc: {result['acc']:.4f}, Epoch_time: {time}\")\n",
    "        file.write(f\"Epoch [{epoch}], last_lr: {result['lrs'][-1]:.5f}, train_loss: {result['test_loss']:.4f}, \"\n",
    "                   f\"test_loss: {result['loss']:.4f}, acc: {result['acc']:.4f}, Epoch_time: {time}\\n\")\n",
    "\n",
    "\n",
    "# This is an implementation of the Resnet9 neural network. not sure if it's good\n",
    "class ResNet(ImageClassification):\n",
    "    def __init__(self, in_channels, num_class):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = create_conv_layer(in_channels, 64)\n",
    "        self.conv2 = create_conv_layer(64, 128, pool=True)\n",
    "        self.res1 = nn.Sequential(create_conv_layer(128, 128), create_conv_layer(128, 128))\n",
    "        self.conv3 = create_conv_layer(128, 256, pool=True)\n",
    "        self.conv4 = create_conv_layer(256, 512, pool=True)\n",
    "        self.res2 = nn.Sequential(create_conv_layer(512, 512), create_conv_layer(512, 512, ))\n",
    "        self.classifier = nn.Sequential(nn.MaxPool2d(4), nn.Flatten(), nn.Linear(512, num_class))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        output = self.conv1(inputs)\n",
    "        output = self.conv2(output)\n",
    "        output = self.res1(output) + output\n",
    "        output = self.conv3(output)\n",
    "        output = self.conv4(output)\n",
    "        output = self.res2(output) + output\n",
    "        output = self.classifier(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "# Create a layer of the convolutional layer\n",
    "# Input: number of in channels, number of out channels, activation function, true if pooling, normalize or\n",
    "# initialization are enabled, false otherwise\n",
    "# Output: Sequential object representing a convolutional layer of the model\n",
    "def create_conv_layer(in_channels, out_channels, activation='relu', pool=False, normalize=True, init=True):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)]\n",
    "\n",
    "    if init and activation == 'relu':\n",
    "        torch.nn.init.kaiming_uniform_(layers[0].weight, nonlinearity='relu')\n",
    "    elif init and activation == 'leaky':\n",
    "        torch.nn.init.kaiming_uniform_(layers[0].weight)\n",
    "\n",
    "    if normalize:\n",
    "        layers.append(nn.BatchNorm2d(out_channels))\n",
    "\n",
    "    if activation == 'relu':\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "    elif activation == 'leaky':\n",
    "        layers.append(nn.LeakyReLU(inplace=True))\n",
    "\n",
    "    if pool:\n",
    "        layers.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# Test function\n",
    "# Input: model and dataloader\n",
    "# Output: Dictionary entry of the loss and accuracy\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    output = [model.testing_step(batch) for batch in loader]\n",
    "    return model.testing_end(output)\n",
    "\n",
    "\n",
    "# Returns the learning rate\n",
    "# Input: Pytorch optimizer object\n",
    "# Output: Float for the learning rate\n",
    "def get_learning_rate(optimizer):\n",
    "    for param in optimizer.param_groups:\n",
    "        return param['lr']\n",
    "\n",
    "\n",
    "# Main training function\n",
    "# Input: Max number of epochs, learning rate, model, train and test dataloaders, weight_decay,\n",
    "# max accuracy where the model will stop training, float for weight decay, optimizer function, filename for logging\n",
    "# Output: Dictionary of history of model's performance\n",
    "def cycle(epochs, max_lr, model, trn_dataloader, tst_dataloader, weight_decay=0, max_acc=65, grad_clip=None,\n",
    "          opt_func=torch.optim.SGD, file=None):\n",
    "    torch.cuda.empty_cache()\n",
    "    history = []\n",
    "\n",
    "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "    # scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs,\n",
    "    #                                                 steps_per_epoch=len(trn_dataloader))\n",
    "\n",
    "    # file.write(f'\\nmax_lr: {max_lr}, weight_decay: {weight_decay}, grad_clip: {grad_clip}, optimizer: {opt_func}\\n')\n",
    "    # file.write('----------------------------------------------------------------------------------------------\\n\\n')\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        start = timeit.default_timer()\n",
    "        model.train()\n",
    "        trn_loss = []\n",
    "        lr_list = []\n",
    "        for batch in trn_dataloader:\n",
    "            loss = model.training_step(batch)\n",
    "            trn_loss.append(loss)\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            if grad_clip:\n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            lr_list.append(get_learning_rate(optimizer))\n",
    "            # scheduler.step()\n",
    "\n",
    "        result = evaluate(model, tst_dataloader)\n",
    "        result['test_loss'] = torch.stack(trn_loss).mean().item()\n",
    "        result['lrs'] = lr_list\n",
    "        end = timeit.default_timer() - start\n",
    "        model.epoch_end(epoch, result, end, file)\n",
    "        history.append(result)\n",
    "        if result['acc'] >= max_acc:\n",
    "            break\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio('dataset2/train', output='output', seed=40093125, ratio=(0.8, 0.2))\n",
    "\n",
    "data_dir = 'dataset'\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Add the command line argument for the learning rate\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-lr\", help='learning rate')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Some hyperparameter and objective function\n",
    "batch_size = 200\n",
    "epoch = 50\n",
    "max_lr = float(args.lr)\n",
    "grad_clip = 0.1\n",
    "weight_decay = 1e-4\n",
    "max_acc = 0.65\n",
    "obj_func = torch.optim.SGD\n",
    "\n",
    "file = open('test.txt', 'a')\n",
    "\n",
    "\n",
    "# Show part of a batch\n",
    "def show_batch(dataloader):\n",
    "    for images, label in dataloader:\n",
    "        fig, ax = plt.subplots(figsize=(12, 12))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images[:64], nrow=8).permute(1, 2, 0))\n",
    "        plt.show()\n",
    "        break\n",
    "\n",
    "# Plot the graph for the loss and accuracy at the end of a run\n",
    "# Input: History of model's training in dictionary form and string for the title of the file\n",
    "def plot_graph(history, title):\n",
    "    plt.subplot(1, 2, 1)\n",
    "    acc = [x['acc'] for x in history]\n",
    "    plt.plot(acc, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    test_loss = [x['loss'] for x in history]\n",
    "    train_loss = [x.get('test_loss') for x in history]\n",
    "    plt.plot(test_loss, '-x')\n",
    "    plt.plot(train_loss, '-o')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and test loss')\n",
    "    plt.legend(['test loss', 'training loss'])\n",
    "\n",
    "    plt.savefig(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# print(os.listdir(data_dir))\n",
    "# classes = os.listdir(data_dir + '/train')\n",
    "# print(classes)\n",
    "\n",
    "# Normalizes the data by setting the mean to 0 and variance by 1.\n",
    "# Also data augmentation, pads the image by 4 pixels, then take a random crop of 32x32 and then\n",
    "# there is a 50% chance of the image being flipped horizontally\n",
    "# This happens at every epoch, so the model sees slightly different versions of the images every time\n",
    "train_tfms = tt.Compose([tt.RandomCrop(48, padding=4, padding_mode='reflect'),\n",
    "                         tt.RandomHorizontalFlip(),\n",
    "                         tt.ToTensor()])\n",
    "\n",
    "test_tfms = tt.Compose([tt.ToTensor()])\n",
    "\n",
    "# Datasets\n",
    "train_dataset = ImageFolder(data_dir + '/train', train_tfms)\n",
    "test_dataset = ImageFolder(data_dir + '/test', test_tfms)\n",
    "val_dataset = ImageFolder(data_dir + '/val', test_tfms)\n",
    "\n",
    "# DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=3, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size * 3, num_workers=3, pin_memory=True)\n",
    "validation_dataloader = DataLoader(val_dataset, batch_size * 3, num_workers=3, pin_memory=True)\n",
    "\n",
    "# show_batch(test_dataloader)\n",
    "\n",
    "# Get the device that will be used to train the model\n",
    "# It will be cuda if your GPU is available or cpu\n",
    "device = device_function.get_device()\n",
    "print(device)\n",
    "\n",
    "# Wrap the dataloader to put it to the device\n",
    "train_dataloader = device_function.DeviceDataloader(train_dataloader, device)\n",
    "test_dataloader = device_function.DeviceDataloader(test_dataloader, device)\n",
    "validation_dataloader = device_function.DeviceDataloader(validation_dataloader, device)\n",
    "#\n",
    "for i in range(3):\n",
    "    filename = \"test\" + str(i) + \".png\"\n",
    "\n",
    "    # Create the model ConvNetwork and put it on the device\n",
    "    model = device_function.to_device(convnet.ResNet(3, 7), device)\n",
    "    #\n",
    "    # History is just to get the history of the loss and accuracy, mostly to see how the model\n",
    "    # evolves\n",
    "    history = [convnet.evaluate(model, validation_dataloader)]\n",
    "    print(f\"Epoch [{0}], \"\n",
    "          f\"test_loss: {history[0]['loss']:.4f}, acc: {history[0]['acc']:.4f}, Epoch_time: {0}\")\n",
    "    file.write(f\"Epoch [{0}], \"\n",
    "               f\"test_loss: {history[0]['loss']:.4f}, acc: {history[0]['acc']:.4f}, Epoch_time: {0}\\n\")\n",
    "    #\n",
    "    #\n",
    "    start = timeit.default_timer()\n",
    "    # Training step is the main training function\n",
    "    history += convnet.cycle(epoch, max_lr, model, train_dataloader, validation_dataloader, max_acc=max_acc,\n",
    "                             grad_clip=grad_clip, weight_decay=weight_decay, opt_func=obj_func, file=file)\n",
    "\n",
    "    # Orion helper function, need to comment it out when not doing cross-validation\n",
    "    # report_objective(history[-1]['loss'])\n",
    "\n",
    "    duration = timeit.default_timer() - start\n",
    "    plot_graph(history, filename)\n",
    "    print(datetime.timedelta(seconds=duration))\n",
    "    file.write(str(datetime.timedelta(seconds=duration)) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGGNET16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data augmentation to train the model with more data, so it generalizes better\n",
    "train_datagen = ImageDataGenerator(\n",
    "        # rescale = 1./255,\n",
    "        validation_split = 0.2,                         \n",
    "        # rotation_range=5,\n",
    "        # width_shift_range=0.2,\n",
    "        # height_shift_range=0.2,\n",
    "        # shear_range=0.2,\n",
    "        # horizontal_flip=True,\n",
    "        # vertical_flip=True,\n",
    "        # fill_mode='nearest'\n",
    "        )\n",
    "\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    # rescale = 1./255,\n",
    "    validation_split = 0.2\n",
    "    )\n",
    "\n",
    "test_datagen  = ImageDataGenerator(\n",
    "    # rescale = 1./255\n",
    "    )\n",
    "\n",
    "# Get the training and test data and initialize train/validation/test sets\n",
    "train_dataset = train_datagen.flow_from_directory(directory=\"face_recognition/train\", target_size=(48, 48), class_mode=\"categorical\", subset=\"training\", batch_size=64)\n",
    "\n",
    "valid_dataset = train_datagen.flow_from_directory(directory=\"face_recognition/train\", target_size=(48, 48), class_mode=\"categorical\", subset=\"validation\", batch_size=64)\n",
    "\n",
    "test_dataset = train_datagen.flow_from_directory(directory=\"face_recognition/test\", target_size=(48, 48), class_mode=\"categorical\", batch_size=64)\n",
    "\n",
    "# VGG16 is a simple and widely used Convolutional Neural Network Architecture used for ImageNet,\n",
    "# a large visual database project used in visual object recognition software research\n",
    "base_model = VGG16(input_shape = (48, 48, 3), include_top = False, weights = \"imagenet\")\n",
    "\n",
    "# We want to have a deep neural network, but we do not want to spend much time training it\n",
    "# That is why, we freeze the weights of the layers, and use a pretrained model with already useful weights\n",
    "for layer in base_model.layers[:-4]:\n",
    "    layer.trainable=False\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "# Add Dropout, which is a regularization method that efficiently approximates training a large number of neural networks and avoids co-adaptations\n",
    "# model.add(Dropout(0.5))\n",
    "# Add a Flatten layer to squash the 3 dimensions of an image to a single dimension\n",
    "model.add(Flatten())\n",
    "# Batch normalization is similar to input normalization, but it is computed at minibatch level in the internal layers\n",
    "model.add(BatchNormalization())\n",
    "# Add a Dense layer at the top of the Convolution layer to classify the images\n",
    "model.add(Dense(32, kernel_initializer=\"he_uniform\"))\n",
    "# Add Batch normalization, which is similar to input normalization, but it is computed at minibatch level in the internal layers\n",
    "model.add(BatchNormalization())\n",
    "# Add relu(Rectified Linear Unit) activation to each layers so that all the negative values are not passed to the next layer\n",
    "model.add(Activation(\"relu\"))\n",
    "# Add Dropout, which is a regularization method that efficiently approximates training a large number of neural networks and avoids co-adaptations\n",
    "# model.add(Dropout(0.5))\n",
    "# Add a Dense layer at the top of the Convolution layer to classify the images\n",
    "model.add(Dense(32, kernel_initializer=\"he_uniform\"))\n",
    "# Add Batch normalization, which is similar to input normalization, but it is computed at minibatch level in the internal layers\n",
    "model.add(BatchNormalization())\n",
    "# Add relu(Rectified Linear Unit) activation to each layers so that all the negative values are not passed to the next layer\n",
    "model.add(Activation(\"relu\"))\n",
    "# Add Dropout, which is a regularization method that efficiently approximates training a large number of neural networks and avoids co-adaptations\n",
    "# model.add(Dropout(0.5))\n",
    "# Add a Dense layer at the top of the Convolution layer to classify the images\n",
    "model.add(Dense(32, kernel_initializer=\"he_uniform\"))\n",
    "# Add Batch normalization, which is similar to input normalization, but it is computed at minibatch level in the internal layers\n",
    "model.add(BatchNormalization())\n",
    "# Add relu(Rectified Linear Unit) activation to each layers so that all the negative values are not passed to the next layer\n",
    "model.add(Activation(\"relu\"))\n",
    "# 7 unit Dense layer since we have 7 classes to predict \n",
    "model.add(Dense(7, activation=\"softmax\"))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "metrics = [\n",
    "    BinaryAccuracy(name=\"accuracy\"),\n",
    "    Precision(name=\"precision\"),\n",
    "    Recall(name=\"recall\")\n",
    "]\n",
    "\n",
    "# Use Adam optimizer to reach the global minima whilce training the model\n",
    "# If it is stuck in local minima while training then the Adam optimiser will help to get out of local minima and reach global minima\n",
    "# \n",
    "model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=metrics)\n",
    "\n",
    "model.fit(train_dataset, validation_data=valid_dataset, epochs=5, verbose=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}